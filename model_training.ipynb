{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Izukfcttsyrp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import keras_efficientnet_v2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eX4VTCxottro"
      },
      "source": [
        "## Import and process data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "t3U7ulqbtdrY"
      },
      "outputs": [],
      "source": [
        "raw_data = pd.read_csv('marketing_sample_for_myntra_com-ecommerce__20190601_20190831__15k_data.csv', on_bad_lines='skip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okGvT5OTvWQo",
        "outputId": "0e5acb04-203f-47d8-fce9-69abb1260b65"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(14231, 25)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAWKBcNouEf_",
        "outputId": "76a11f0a-3aa9-44ee-fb95-5b9faf27c7e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['uniq_id', 'crawl_timestamp', 'product_id', 'link', 'size',\n",
              "       'variant_sku', 'brand', 'care_instructions', 'dominant_material',\n",
              "       'title', 'actual_color', 'dominant_color', 'product_type', 'images',\n",
              "       'body', 'product_details', 'size_fit', 'complete_the_look', 'type',\n",
              "       'variant_price', 'variant_compare_at_price', 'ideal_for', 'is_in_stock',\n",
              "       'inventory', 'specifications'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_data.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xN6YYaovuh4"
      },
      "source": [
        "### Selecting the feature columns\n",
        "- 'dominant_material', 'dominant_color', and 'product_type' would be used as labels.\n",
        "\n",
        "- 'images' would be used to extract images.\n",
        "\n",
        "- 'ideal_for' would be used to separate women's data from men's."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "exP6sZMLuJgw"
      },
      "outputs": [],
      "source": [
        "cat_columns = ['dominant_material','dominant_color', 'product_type', 'images', 'ideal_for']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oIXeNGxmubGK"
      },
      "outputs": [],
      "source": [
        "data = raw_data[cat_columns]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Separating womens from mens and dropping the missing entries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dGGHtrl8usxo"
      },
      "outputs": [],
      "source": [
        "women_data = data[data['ideal_for']=='Women']\n",
        "women_data.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dH8IS9Msvm0_",
        "outputId": "b3675ad6-c3af-4f1f-cff8-5f42499e9417"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dominant_material</th>\n",
              "      <th>dominant_color</th>\n",
              "      <th>product_type</th>\n",
              "      <th>images</th>\n",
              "      <th>ideal_for</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Polyester</td>\n",
              "      <td>Black</td>\n",
              "      <td>Top</td>\n",
              "      <td>http://assets.myntassets.com/v1/assets/images/...</td>\n",
              "      <td>Women</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Chiffon</td>\n",
              "      <td>Pink</td>\n",
              "      <td>Dupatta</td>\n",
              "      <td>http://assets.myntassets.com/v1/assets/images/...</td>\n",
              "      <td>Women</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Polyester</td>\n",
              "      <td>Maroon</td>\n",
              "      <td>A-Line Kurta</td>\n",
              "      <td>http://assets.myntassets.com/v1/assets/images/...</td>\n",
              "      <td>Women</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Viscose Rayon</td>\n",
              "      <td>Navy</td>\n",
              "      <td>Printed Palazzos</td>\n",
              "      <td>http://assets.myntassets.com/v1/assets/images/...</td>\n",
              "      <td>Women</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Rayon</td>\n",
              "      <td>Blue</td>\n",
              "      <td>Straight Kurta</td>\n",
              "      <td>http://assets.myntassets.com/v1/assets/images/...</td>\n",
              "      <td>Women</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   dominant_material dominant_color      product_type  \\\n",
              "0          Polyester          Black               Top   \n",
              "3            Chiffon           Pink           Dupatta   \n",
              "8          Polyester         Maroon      A-Line Kurta   \n",
              "10     Viscose Rayon           Navy  Printed Palazzos   \n",
              "11             Rayon           Blue    Straight Kurta   \n",
              "\n",
              "                                               images ideal_for  \n",
              "0   http://assets.myntassets.com/v1/assets/images/...     Women  \n",
              "3   http://assets.myntassets.com/v1/assets/images/...     Women  \n",
              "8   http://assets.myntassets.com/v1/assets/images/...     Women  \n",
              "10  http://assets.myntassets.com/v1/assets/images/...     Women  \n",
              "11  http://assets.myntassets.com/v1/assets/images/...     Women  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "women_data.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### As we can see below there are too many classes of product types, and material types. Many of the classes are of similar kind to other ones. Hence, products of similar types are merged into one category "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPPIfIBnxXKJ",
        "outputId": "eb950a73-0976-403e-94e1-577c6c3c449a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(206,\n",
              " array(['Top', 'Dupatta', 'A-Line Kurta', 'Printed Palazzos',\n",
              "        'Straight Kurta', 'Kurta with Palazzos', 'Shrug',\n",
              "        'Straight Palazzo', 'Kurta with Trousers & Dupatta', 'Tunic',\n",
              "        'Lehenga & Blouse with Dupatta', 'Treggings', 'A-Line Dress',\n",
              "        'Flared Palazzo', 'Kurta with Churidar & Dupatta',\n",
              "        'Cropped Palazzo', 'Straight Kurti', 'Maxi Dress', 'Midi Skirt',\n",
              "        'Regular Trousers', 'Fit and Flare Dress', 'Solid Trousers',\n",
              "        'Layered A-Line Kurta', 'Skirt', 'Saree', 'Kurta with Churidar',\n",
              "        'Shawl', 'Wide Leg Palazzo', 'Kurta with Trousers',\n",
              "        'Kurti with Trousers', 'Kurti', 'Kurti with Palazzos',\n",
              "        'Layered Maxi Dress', 'Printed Kurta', 'Winter Kurta',\n",
              "        'Ready to Wear Lehenga with Blouse', 'Kaftan Top', 'Midi Dress',\n",
              "        'Lehenga & Blouse', 'Solid Kurta', 'A-Line Kurti', 'Maxi Skirt',\n",
              "        'A-Line Top', 'Fusion Kurta', 'Solid Maxi Dress',\n",
              "        'Kurta with Ethnic Jacket', 'Maxi Flared Skirt',\n",
              "        'Kurta with Printed Inner', 'Shirt Dress', 'Flared Solid Palazzos',\n",
              "        'Semi-Stitched Lehenga & Unstitched Blouse with Dupatta',\n",
              "        'Palazzos', 'Parallel Trousers', 'Flared Skirt',\n",
              "        'Layered Straight Kurta', 'Anarkali Kurta', 'High-Low Top',\n",
              "        'Pathani Kurta', 'Layered Kurta', 'Lehenga Choli',\n",
              "        'Lehenga with Blouse', 'Kurta with Dhoti Pants & Dupatta',\n",
              "        'Wide Leg Solid Palazzos', 'Printed Empire Dress',\n",
              "        'Printed Shirt Dress', 'Empire Dress', 'Kurta with Palazzo',\n",
              "        'Sweater', 'Ethnic Jacket', 'Churidar Kurta with Dupatta',\n",
              "        'Waistcoat', 'Denim Kurta', 'Maxi Dress with Shrug', 'Trousers',\n",
              "        'A-Line Skirt', 'Wide Leg Hem Design Palazzos',\n",
              "        'Kurta with Sharara', 'Wrap Dress', 'Kurta with Sharara & Dupatta',\n",
              "        'Churidar', 'Dhoti Pants', 'Kurta with Leggings & Dupatta',\n",
              "        'Kurta with Longline Ethnic Jacket', 'Skirt with Tassels',\n",
              "        'Tunic with Bell Sleeves', 'Maxi Dress with Ethnic Jacket',\n",
              "        'Kurta with Skirt', 'Jumpsuit', 'Solid Palazzo', 'High-Low Kurta',\n",
              "        'Casual Trousers', 'Fit & Flare Dress', 'Angrakha Kurta',\n",
              "        'Long Kurta', 'LIVA Kurta', 'Leggings',\n",
              "        'Embroidered Kurta with Palazzos & Dupatta', 'Palazzo',\n",
              "        'A-Line Tunic', 'Blouson Top', 'Lehenga Choli with Dupatta',\n",
              "        'Lehenga with Choli', 'Cold-Shoulder Kaftan Kurta',\n",
              "        'Cropped Trousers', 'Kurta with Skirt & Dupatta',\n",
              "        'Anarkali Churidar Kurta with Dupatta', 'Checked Maxi Dress',\n",
              "        'Palazzo Trouser', 'Sweater Kurta', 'Self Design Top', 'Cardigan',\n",
              "        'Top with Palazzos', 'Dress Material', 'Shirt', 'Casual Shirt',\n",
              "        'Clothing Set', 'Top with Skirt & Dupatta',\n",
              "        'Kurta with Salwar & Dupatta', 'Lehenga & Choli with Dupatta',\n",
              "        'Shirt Style Top', 'Culottes', 'Peplum Top',\n",
              "        'Flared Printed Palazzos', 'Striped Kurta', 'Churidar Leggings',\n",
              "        'Regular Top', 'Chambray Kurta', 'Kurta with Patiala & Dupatta',\n",
              "        'Flared Solid Silk Palazzos', 'Earrings', 'Woven Kurta',\n",
              "        'A-Line Flared Skirt', 'Flared Striped Palazzos',\n",
              "        'Kurta with Pyjamas & Dupatta',\n",
              "        'BIBA Coral Red Top with Lace Detail', 'Cigarette Trousers',\n",
              "        'Straight Hem Design Palazzos', 'Solid Kurta Set',\n",
              "        'Self Design Tunic', 'High-Low Kurti',\n",
              "        'Maxi Dress With Printed Detail', 'Kurti with Pyjamas',\n",
              "        'Tailored Jacket', 'A-Line Layered Dress',\n",
              "        'A-Line Kurta with Jacket', 'High-Low Tunic', 'Maxi Tiered Skirt',\n",
              "        'Kurti with Dhoti Pants', 'Maxi Dress with Jacket', 'Wrap Top',\n",
              "        'Salwar Suit with Dupatta', 'Kurti with Trousers & Dupatta',\n",
              "        'Kurta with Palazzo & Dupatta',\n",
              "        'Kurta with Palazzo Trousers & Dupatta', 'Kurta with Dhoti Pants',\n",
              "        'Kurta with Salwar', 'Striped Kurti',\n",
              "        'Kurta with Palazzos and Dupatta', 'Midi Flared Skirt',\n",
              "        'Tunic Shirt', 'Kurti with Skirt & Dupatta',\n",
              "        'Cold-Shoulder A-Line Kurta', 'Flared Sharara', 'Khaki Kurta',\n",
              "        'Solid Pullover', 'Kurti with Patiala', 'Maxi Dress with Cape',\n",
              "        'Kurta with Pyjamas', 'Kurta with Patiala', 'T-shirt', 'Playsuit',\n",
              "        'A-Line Chanderi Cotton Kurta', 'Layered Top',\n",
              "        'Denim Kurta with Metallic Detail', 'Flared Layered Palazzos',\n",
              "        'Kurta with Printed Palazzos', 'Flat-Front Trousers',\n",
              "        'Kaftan Kurti with Pants',\n",
              "        'Kurta with Ethnic Jacket Churidar & Dupatta',\n",
              "        'Kurta with Churidar and Ethnic Jacket', 'Angrakha Anarkali Kurta',\n",
              "        'Printed Top with Palazzos & Jacket',\n",
              "        'Top with Palazzos and Dupatta', 'Kurti with Skirt', 'Denim Shirt',\n",
              "        'Layered Tunic', 'Chanderi Blend Kurta', 'Shirt-Style Top',\n",
              "        'Cold-Shoulder Top', 'Kurta with Palazzos with Dupatta',\n",
              "        'Silk Kurta', 'Maxi Dress with Printed Jacket',\n",
              "        'Maxi Dress with Printed Layer', 'Top with Embroidered Detail',\n",
              "        'Polyester Kurta', 'Solid Shirt Style Top with Ruffles',\n",
              "        'Anarkali Kurta with Waistcoat', 'Kurti with Churidar & Dupatta',\n",
              "        'Anarkali Kurta with Dupatta', 'Cold Shoulder A-Line Kurta',\n",
              "        'Jewellery', 'Tunic with Crochet Trims', 'Handloom Kurta',\n",
              "        'Sweater Dress', 'Handloom Kurtas', 'Flared Hem Design Palazzos'],\n",
              "       dtype=object))"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(women_data.product_type.unique()), women_data.product_type.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-saqtddLxePB",
        "outputId": "702ee344-0db0-43a4-89db-1cf55bc1e2a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(38,\n",
              " array(['Polyester', 'Chiffon', 'Viscose Rayon', 'Rayon', 'Silk',\n",
              "        'viscose', 'cotton', 'Cotton', 'Net', 'Chanderi', 'polyester',\n",
              "        'Liva', 'Linen', 'Acrylic', 'rayon', 'acrylic', 'Viscose', 'Modal',\n",
              "        'Georgette', 'liva', 'Velvet', 'silk', 'tencil', 'Crepe',\n",
              "        'Poly Silk', 'Satin', 'modal', 'geicha', 'Dupion', 'Pure Silk',\n",
              "        'Wool', 'georgette', 'Khadi', 'Nylon', 'lyocell', 'linen', 'SILK',\n",
              "        'wool'], dtype=object))"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(women_data.dominant_material.unique()),women_data.dominant_material.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KerfSaLRxpNJ",
        "outputId": "dd93acc8-923f-4890-b5b9-d91015dca465"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(41,\n",
              " array(['Black', 'Pink', 'Maroon', 'Navy', 'Blue', 'Coffee Brown', 'White',\n",
              "        'Red', 'Charcoal', 'Yellow', 'Beige', 'Orange', 'Grey',\n",
              "        'Sea Green', 'Green', 'Olive', 'Mustard', 'Fuchsia', 'Brown',\n",
              "        'Teal', 'Purple', 'Rust', 'Coral', 'Lime Green', 'Magenta',\n",
              "        'Turquoise Blue', 'Lavender', 'Taupe', 'Mauve', 'Burgundy',\n",
              "        'Silver', 'Khaki', 'Cream', 'Peach', 'Fluorescent Green', 'Rose',\n",
              "        'Off White', 'Multi', 'Tan', 'Gold', 'Dark Green'], dtype=object))"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(women_data.dominant_color.unique()),women_data.dominant_color.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_OBjvzJxpoJ",
        "outputId": "85abf26f-b551-47bb-d80c-fb94fb9c60a9"
      },
      "outputs": [],
      "source": [
        "\n",
        "for index, value in women_data.product_type.iteritems():\n",
        "    if 'Kurta' in value or 'Kurti' in value:\n",
        "        women_data.product_type[index] = 'Kurta'\n",
        "    if 'blouse' in value.lower():\n",
        "        women_data.product_type[index] = 'Blouse'\n",
        "    if 'dress' in value.lower():\n",
        "        women_data.product_type[index] = 'Dress'\n",
        "    if 'skirt' in value.lower():\n",
        "        women_data.product_type[index] = 'Skirt'\n",
        "    if 'palazzo' in value.lower():\n",
        "        women_data.product_type[index] = 'Palazzo'\n",
        "    if 'top' in value.lower():\n",
        "        women_data.product_type[index] = 'Top'\n",
        "    if 'shirt' in value.lower():\n",
        "        women_data.product_type[index] = 'Shirt'\n",
        "    if 'dupatta' in value.lower():\n",
        "        women_data.product_type[index] = 'Dupatta'\n",
        "    if 'trouser' in value.lower():\n",
        "        women_data.product_type[index] = 'Trousers'\n",
        "    if 'tunic' in value.lower():\n",
        "        women_data.product_type[index] = 'Tunic'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86EPUJiKx3Q9",
        "outputId": "a56394a5-96da-4066-9889-eefaac18bebb"
      },
      "outputs": [],
      "source": [
        "for index, value in women_data.dominant_material.iteritems():\n",
        "    if 'rayon' in value.lower():\n",
        "        women_data.dominant_material[index] = 'Rayon'\n",
        "    if 'polyester' in value.lower():\n",
        "        women_data.dominant_material[index] = 'Polyester'\n",
        "    if 'cotton' in value.lower():\n",
        "        women_data.dominant_material[index] = 'Cotton'\n",
        "    if 'acrylic' in value.lower():\n",
        "        women_data.dominant_material[index] = 'Acrylic'\n",
        "    if 'silk' in value.lower():\n",
        "        women_data.dominant_material[index] = 'Silk'\n",
        "    if 'wool' in value.lower():\n",
        "        women_data.dominant_material[index] = 'Wool'\n",
        "    if 'viscose' in value.lower():\n",
        "        women_data.dominant_material[index] = 'Viscose'\n",
        "    if 'linen' in value.lower():\n",
        "        women_data.dominant_material[index] = 'linen'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Making final list of classses and converting classes from strings to integers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "b2bFB10oyIAm"
      },
      "outputs": [],
      "source": [
        "color_classes = list(women_data.dominant_color.unique())\n",
        "material_classes = list(women_data.dominant_material.unique())\n",
        "product_type_classes = list(women_data.product_type.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKz8E4OyydPx",
        "outputId": "e20d2f9a-9633-47b0-fe8b-c956cf21f7e1"
      },
      "outputs": [],
      "source": [
        "women_data['dominant_color'].replace(color_classes, [i for i in range(len(color_classes))], inplace=True)\n",
        "women_data['dominant_material'].replace(material_classes, [i for i in range(len(material_classes))], inplace=True)\n",
        "women_data['product_type'].replace(product_type_classes, [i for i in range(len(product_type_classes))], inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHjnqixfuVjL"
      },
      "source": [
        "### We already have the data downloaded so the below commented steps won't be necessary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Every data entry has multiple urls of images. Only the first image url from those are kept for each entry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "3jRD7v0pync-"
      },
      "outputs": [],
      "source": [
        "# for index, value in women_data.images.iteritems():\n",
        "#     women_data.images[index] = value.split()[0]\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "l65EmS-Iy-3j"
      },
      "outputs": [],
      "source": [
        "# images_url = list(women_data.images)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "BXtAFQZz3vh-"
      },
      "outputs": [],
      "source": [
        "# len(images_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "H0nkFFv1zFj6"
      },
      "outputs": [],
      "source": [
        "# os.mkdir('images')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Xn2Z-Kzk4Q-8"
      },
      "outputs": [],
      "source": [
        "# for i, x in enumerate(images_url):\n",
        "#     utils.get_file(os.path.join('/images', f\"{i}.jpg\"), origin=x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JddkBLDueOr"
      },
      "source": [
        "Below step is to make sure the data is retrieved in the right order since the data downloaded from  women_data['images'] were in order - 0,1,2,3,4,..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "n6aRs0wE5BEu"
      },
      "outputs": [],
      "source": [
        "images = os.listdir('images')\n",
        "images_idx = [i for i in range(len(images))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wq3I1KkK5ZR0",
        "outputId": "a028f1ca-ca0b-447c-f61f-7d0e2c57a4b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7381\n"
          ]
        }
      ],
      "source": [
        "print(len(images_idx))\n",
        "assert len(images_idx) == women_data.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Converting the images into arrays and creating a dataset which can be fed into the neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2_FqU3tzayi",
        "outputId": "1d9be8e1-a805-4201-8abf-98d9d7552e8d"
      },
      "outputs": [],
      "source": [
        "train_image = []\n",
        "for i in images_idx:\n",
        "    path = os.path.join('images', str(i))\n",
        "    img = image.load_img(path + '.jpg', target_size=(224,224,3))\n",
        "    img = image.img_to_array(img)\n",
        "    img = img/255\n",
        "    train_image.append(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "NV1X12wqzutK"
      },
      "outputs": [],
      "source": [
        "X = np.array(train_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1xq-nlTzwqZ",
        "outputId": "db876340-1d67-438e-9760-dbd5c10d041b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7381, 224, 224, 3)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAFaAdf5zyba",
        "outputId": "820d7bbe-1b98-4d9b-a350-753d2a418903"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((7381,), (7381,), (7381,))"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "color_labels = np.array(women_data.dominant_color)\n",
        "type_labels = np.array(women_data.product_type)\n",
        "material_labels = np.array(women_data.dominant_material)\n",
        "color_labels.shape, type_labels.shape, material_labels.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 7381 images and 7381 labels each for color, product type, material type are available in the final dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \n",
        "## Training the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### EfficientNet-V2-B1 is used as the base model and transfer learning with further fine tuning is used to train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "5fzf2_UAEZAf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>>> Load pretrained from: C:\\Users\\suraj\\.keras\\models/efficientnetv2\\efficientnetv2-b1-imagenet.h5\n"
          ]
        }
      ],
      "source": [
        "base_model = keras_efficientnet_v2.EfficientNetV2B1(pretrained='imagenet',num_classes=0, input_shape=(224,224,3), include_preprocessing=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### The top layers after the base model diverge into three branches for three different output, one each for predicting color, type, and material."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "fRlKdRlvEUz8"
      },
      "outputs": [],
      "source": [
        "x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "color_layer = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "color_layer = tf.keras.layers.Dropout(0.2)(color_layer)\n",
        "color_layer = tf.keras.layers.Dense(256, activation='relu')(color_layer)\n",
        "color_output = tf.keras.layers.Dense(len(color_classes), activation='softmax',name='color')(color_layer)\n",
        "\n",
        "type_layer = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "type_layer = tf.keras.layers.Dropout(0.2)(type_layer)\n",
        "type_layer = tf.keras.layers.Dense(256, activation='relu')(type_layer)\n",
        "type_output = tf.keras.layers.Dense(len(product_type_classes), activation='softmax',name='type')(type_layer)\n",
        "\n",
        "material_layer = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "material_layer = tf.keras.layers.Dropout(0.2)(material_layer)\n",
        "material_layer = tf.keras.layers.Dense(256, activation='relu')(material_layer)\n",
        "material_output = tf.keras.layers.Dense(len(material_classes), activation='softmax', name='material')(material_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "lCCtq4bUElku"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Model(inputs=base_model.input, outputs= [color_output, type_output, material_output])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The layers of the base model are frozen initially to begin transfer learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [],
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1661/1661 [==============================] - 278s 162ms/step - loss: 4.7691 - color_loss: 1.8975 - type_loss: 1.2402 - material_loss: 1.6315 - color_accuracy: 0.4350 - type_accuracy: 0.6218 - material_accuracy: 0.4341 - val_loss: 4.3696 - val_color_loss: 1.7058 - val_type_loss: 1.0422 - val_material_loss: 1.6216 - val_color_accuracy: 0.4763 - val_type_accuracy: 0.6279 - val_material_accuracy: 0.4263\n",
            "Epoch 2/10\n",
            "1661/1661 [==============================] - 285s 172ms/step - loss: 4.2616 - color_loss: 1.6357 - type_loss: 1.0695 - material_loss: 1.5565 - color_accuracy: 0.4830 - type_accuracy: 0.6656 - material_accuracy: 0.4496 - val_loss: 4.2639 - val_color_loss: 1.6967 - val_type_loss: 0.9487 - val_material_loss: 1.6184 - val_color_accuracy: 0.4844 - val_type_accuracy: 0.6658 - val_material_accuracy: 0.4005\n",
            "Epoch 3/10\n",
            "1661/1661 [==============================] - 282s 170ms/step - loss: 4.0012 - color_loss: 1.5193 - type_loss: 0.9796 - material_loss: 1.5023 - color_accuracy: 0.5187 - type_accuracy: 0.6771 - material_accuracy: 0.4664 - val_loss: 4.0384 - val_color_loss: 1.5549 - val_type_loss: 0.9059 - val_material_loss: 1.5776 - val_color_accuracy: 0.5277 - val_type_accuracy: 0.6928 - val_material_accuracy: 0.4438\n",
            "Epoch 4/10\n",
            "1661/1661 [==============================] - 275s 165ms/step - loss: 3.8187 - color_loss: 1.4347 - type_loss: 0.9183 - material_loss: 1.4656 - color_accuracy: 0.5292 - type_accuracy: 0.7013 - material_accuracy: 0.4762 - val_loss: 4.0659 - val_color_loss: 1.6050 - val_type_loss: 0.9038 - val_material_loss: 1.5570 - val_color_accuracy: 0.5264 - val_type_accuracy: 0.6915 - val_material_accuracy: 0.4317\n",
            "Epoch 5/10\n",
            "1661/1661 [==============================] - 272s 164ms/step - loss: 3.6256 - color_loss: 1.3522 - type_loss: 0.8510 - material_loss: 1.4223 - color_accuracy: 0.5584 - type_accuracy: 0.7183 - material_accuracy: 0.4881 - val_loss: 4.0215 - val_color_loss: 1.5889 - val_type_loss: 0.9301 - val_material_loss: 1.5025 - val_color_accuracy: 0.5210 - val_type_accuracy: 0.6617 - val_material_accuracy: 0.4438\n",
            "Epoch 6/10\n",
            "1661/1661 [==============================] - 274s 165ms/step - loss: 3.4766 - color_loss: 1.2758 - type_loss: 0.8163 - material_loss: 1.3844 - color_accuracy: 0.5815 - type_accuracy: 0.7282 - material_accuracy: 0.5017 - val_loss: 3.8820 - val_color_loss: 1.5122 - val_type_loss: 0.8564 - val_material_loss: 1.5135 - val_color_accuracy: 0.5494 - val_type_accuracy: 0.6928 - val_material_accuracy: 0.4384\n",
            "Epoch 7/10\n",
            "1661/1661 [==============================] - 273s 164ms/step - loss: 3.3178 - color_loss: 1.2137 - type_loss: 0.7595 - material_loss: 1.3447 - color_accuracy: 0.5933 - type_accuracy: 0.7451 - material_accuracy: 0.5136 - val_loss: 4.2001 - val_color_loss: 1.6510 - val_type_loss: 0.9772 - val_material_loss: 1.5719 - val_color_accuracy: 0.5575 - val_type_accuracy: 0.6861 - val_material_accuracy: 0.4438\n",
            "Epoch 8/10\n",
            "1661/1661 [==============================] - 276s 166ms/step - loss: 3.1969 - color_loss: 1.1667 - type_loss: 0.7172 - material_loss: 1.3130 - color_accuracy: 0.6110 - type_accuracy: 0.7632 - material_accuracy: 0.5175 - val_loss: 3.9543 - val_color_loss: 1.5857 - val_type_loss: 0.8478 - val_material_loss: 1.5208 - val_color_accuracy: 0.5521 - val_type_accuracy: 0.7348 - val_material_accuracy: 0.4723\n",
            "Epoch 9/10\n",
            "1661/1661 [==============================] - 281s 169ms/step - loss: 3.0505 - color_loss: 1.0866 - type_loss: 0.6887 - material_loss: 1.2753 - color_accuracy: 0.6319 - type_accuracy: 0.7669 - material_accuracy: 0.5372 - val_loss: 4.1813 - val_color_loss: 1.7126 - val_type_loss: 0.8707 - val_material_loss: 1.5979 - val_color_accuracy: 0.5507 - val_type_accuracy: 0.7361 - val_material_accuracy: 0.4641\n",
            "Epoch 10/10\n",
            "1661/1661 [==============================] - 284s 171ms/step - loss: 2.9496 - color_loss: 1.0519 - type_loss: 0.6508 - material_loss: 1.2469 - color_accuracy: 0.6354 - type_accuracy: 0.7781 - material_accuracy: 0.5449 - val_loss: 4.0526 - val_color_loss: 1.6446 - val_type_loss: 0.8808 - val_material_loss: 1.5272 - val_color_accuracy: 0.5250 - val_type_accuracy: 0.7131 - val_material_accuracy: 0.4736\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer='adam', loss=['sparse_categorical_crossentropy','sparse_categorical_crossentropy','sparse_categorical_crossentropy'], metrics=['accuracy'])\n",
        "history = model.fit(X, [color_labels, type_labels, material_labels],batch_size=4, epochs=10, validation_split=0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('trained_bottom_layers.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first two stacks (out of 5) of the Efficientnet-v2-B1 base model are left frozen since we don't have a huge dataset and the low level features need not necessarily be trained again.\n",
        "\n",
        "Fine-tuning is done for the layers starting from the 3rd stack. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "45"
            ]
          },
          "execution_count": 155,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.layers.index(model.get_layer(name='stack_3_block0_sortcut_conv'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {},
      "outputs": [],
      "source": [
        "for layer in base_model.layers[45:]:\n",
        "    layer.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "fw0F60-V7qJG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1661/1661 [==============================] - 657s 386ms/step - loss: 4.5888 - color_loss: 1.8911 - type_loss: 1.1415 - material_loss: 1.5562 - color_accuracy: 0.4360 - type_accuracy: 0.6436 - material_accuracy: 0.4523 - val_loss: 4.5472 - val_color_loss: 1.9332 - val_type_loss: 0.9635 - val_material_loss: 1.6506 - val_color_accuracy: 0.4655 - val_type_accuracy: 0.6928 - val_material_accuracy: 0.4344\n",
            "Epoch 2/15\n",
            "1661/1661 [==============================] - 677s 408ms/step - loss: 3.9260 - color_loss: 1.5396 - type_loss: 0.9356 - material_loss: 1.4508 - color_accuracy: 0.5206 - type_accuracy: 0.7091 - material_accuracy: 0.4825 - val_loss: 4.3532 - val_color_loss: 1.8059 - val_type_loss: 0.9305 - val_material_loss: 1.6168 - val_color_accuracy: 0.5034 - val_type_accuracy: 0.6874 - val_material_accuracy: 0.4547\n",
            "Epoch 3/15\n",
            "1661/1661 [==============================] - 667s 402ms/step - loss: 3.6374 - color_loss: 1.3966 - type_loss: 0.8460 - material_loss: 1.3947 - color_accuracy: 0.5595 - type_accuracy: 0.7311 - material_accuracy: 0.4976 - val_loss: 4.1434 - val_color_loss: 1.7216 - val_type_loss: 0.8600 - val_material_loss: 1.5618 - val_color_accuracy: 0.5142 - val_type_accuracy: 0.7131 - val_material_accuracy: 0.5020\n",
            "Epoch 4/15\n",
            "1661/1661 [==============================] - 660s 397ms/step - loss: 3.3806 - color_loss: 1.2852 - type_loss: 0.7508 - material_loss: 1.3446 - color_accuracy: 0.5930 - type_accuracy: 0.7529 - material_accuracy: 0.5160 - val_loss: 3.8802 - val_color_loss: 1.5363 - val_type_loss: 0.7990 - val_material_loss: 1.5449 - val_color_accuracy: 0.5629 - val_type_accuracy: 0.7497 - val_material_accuracy: 0.4885\n",
            "Epoch 5/15\n",
            "1661/1661 [==============================] - 665s 401ms/step - loss: 3.2106 - color_loss: 1.2191 - type_loss: 0.6743 - material_loss: 1.3172 - color_accuracy: 0.6182 - type_accuracy: 0.7814 - material_accuracy: 0.5343 - val_loss: 4.2671 - val_color_loss: 1.6608 - val_type_loss: 0.8518 - val_material_loss: 1.7545 - val_color_accuracy: 0.5453 - val_type_accuracy: 0.7618 - val_material_accuracy: 0.4574\n",
            "Epoch 6/15\n",
            "1661/1661 [==============================] - 688s 414ms/step - loss: 2.9746 - color_loss: 1.1065 - type_loss: 0.6172 - material_loss: 1.2509 - color_accuracy: 0.6373 - type_accuracy: 0.7949 - material_accuracy: 0.5516 - val_loss: 4.0031 - val_color_loss: 1.5912 - val_type_loss: 0.7913 - val_material_loss: 1.6206 - val_color_accuracy: 0.5480 - val_type_accuracy: 0.7483 - val_material_accuracy: 0.4465\n",
            "Epoch 7/15\n",
            "1661/1661 [==============================] - 676s 407ms/step - loss: 2.7832 - color_loss: 1.0255 - type_loss: 0.5638 - material_loss: 1.1938 - color_accuracy: 0.6683 - type_accuracy: 0.8141 - material_accuracy: 0.5828 - val_loss: 3.9848 - val_color_loss: 1.6114 - val_type_loss: 0.8420 - val_material_loss: 1.5314 - val_color_accuracy: 0.5318 - val_type_accuracy: 0.7686 - val_material_accuracy: 0.5074\n",
            "Epoch 8/15\n",
            "1661/1661 [==============================] - 680s 409ms/step - loss: 2.5873 - color_loss: 0.9429 - type_loss: 0.5099 - material_loss: 1.1344 - color_accuracy: 0.6921 - type_accuracy: 0.8333 - material_accuracy: 0.6028 - val_loss: 3.9797 - val_color_loss: 1.6185 - val_type_loss: 0.7879 - val_material_loss: 1.5733 - val_color_accuracy: 0.5548 - val_type_accuracy: 0.7645 - val_material_accuracy: 0.4655\n",
            "Epoch 9/15\n",
            "1661/1661 [==============================] - 661s 398ms/step - loss: 2.4388 - color_loss: 0.8885 - type_loss: 0.4662 - material_loss: 1.0841 - color_accuracy: 0.7114 - type_accuracy: 0.8475 - material_accuracy: 0.6149 - val_loss: 4.1200 - val_color_loss: 1.7333 - val_type_loss: 0.8349 - val_material_loss: 1.5519 - val_color_accuracy: 0.5521 - val_type_accuracy: 0.7673 - val_material_accuracy: 0.5142\n",
            "Epoch 10/15\n",
            "1661/1661 [==============================] - 712s 428ms/step - loss: 2.2175 - color_loss: 0.8070 - type_loss: 0.4127 - material_loss: 0.9978 - color_accuracy: 0.7298 - type_accuracy: 0.8659 - material_accuracy: 0.6435 - val_loss: 4.4180 - val_color_loss: 1.7932 - val_type_loss: 0.9191 - val_material_loss: 1.7057 - val_color_accuracy: 0.5765 - val_type_accuracy: 0.7605 - val_material_accuracy: 0.5047\n",
            "Epoch 11/15\n",
            "1661/1661 [==============================] - 678s 408ms/step - loss: 2.0533 - color_loss: 0.7342 - type_loss: 0.3763 - material_loss: 0.9428 - color_accuracy: 0.7582 - type_accuracy: 0.8799 - material_accuracy: 0.6674 - val_loss: 4.8557 - val_color_loss: 1.9995 - val_type_loss: 0.9490 - val_material_loss: 1.9072 - val_color_accuracy: 0.5859 - val_type_accuracy: 0.7700 - val_material_accuracy: 0.5142\n",
            "Epoch 12/15\n",
            "1661/1661 [==============================] - 686s 413ms/step - loss: 1.9088 - color_loss: 0.6820 - type_loss: 0.3590 - material_loss: 0.8679 - color_accuracy: 0.7776 - type_accuracy: 0.8823 - material_accuracy: 0.6968 - val_loss: 4.9280 - val_color_loss: 2.0417 - val_type_loss: 1.0362 - val_material_loss: 1.8501 - val_color_accuracy: 0.5535 - val_type_accuracy: 0.7713 - val_material_accuracy: 0.5196\n",
            "Epoch 13/15\n",
            "1661/1661 [==============================] - 655s 395ms/step - loss: 1.7696 - color_loss: 0.6596 - type_loss: 0.3145 - material_loss: 0.7954 - color_accuracy: 0.7821 - type_accuracy: 0.8928 - material_accuracy: 0.7156 - val_loss: 4.6630 - val_color_loss: 1.8510 - val_type_loss: 1.0845 - val_material_loss: 1.7275 - val_color_accuracy: 0.5819 - val_type_accuracy: 0.7659 - val_material_accuracy: 0.5196\n",
            "Epoch 14/15\n",
            "1661/1661 [==============================] - 683s 411ms/step - loss: 1.5996 - color_loss: 0.5878 - type_loss: 0.2787 - material_loss: 0.7331 - color_accuracy: 0.8022 - type_accuracy: 0.9091 - material_accuracy: 0.7416 - val_loss: 4.7032 - val_color_loss: 1.9608 - val_type_loss: 0.9274 - val_material_loss: 1.8150 - val_color_accuracy: 0.5886 - val_type_accuracy: 0.8024 - val_material_accuracy: 0.5399\n",
            "Epoch 15/15\n",
            "1661/1661 [==============================] - 665s 400ms/step - loss: 1.4915 - color_loss: 0.5408 - type_loss: 0.2724 - material_loss: 0.6783 - color_accuracy: 0.8217 - type_accuracy: 0.9107 - material_accuracy: 0.7617 - val_loss: 5.2886 - val_color_loss: 2.2922 - val_type_loss: 1.1122 - val_material_loss: 1.8842 - val_color_accuracy: 0.5535 - val_type_accuracy: 0.7727 - val_material_accuracy: 0.5440\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer='adam', loss=['sparse_categorical_crossentropy','sparse_categorical_crossentropy','sparse_categorical_crossentropy'], metrics=['accuracy'])\n",
        "history = model.fit(X, [color_labels, type_labels, material_labels],batch_size=4, epochs=15, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A slight but definitely an improvement in the model performance can be seen after fine-tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### The final model and the weights are saved for further uses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "qcFHPYWA7s5d"
      },
      "outputs": [],
      "source": [
        "model.save('final_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### THANK YOU"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "5644cdc60434eeed3898b17d4811b00cc80316056d6ecc0832df57476e051c36"
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('tensorflow')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
